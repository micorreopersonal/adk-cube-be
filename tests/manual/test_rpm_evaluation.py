import asyncio
import time
import json
import os
import sys

# Asegurar que el path del proyecto estÃ© disponible
sys.path.append(os.getcwd())

from app.ai.agents.router_logic import AgentRouter
from app.core.config.config import get_settings

async def run_rpm_test():
    router = AgentRouter()
    settings = get_settings()
    
    print("="*60)
    print("ðŸš€ INICIANDO TEST DE EVALUACIÃ“N DE RPM / CUOTA API")
    print(f"Proyecto: {settings.PROJECT_ID}")
    print(f"Backend: Vertex AI (v1) en {settings.REGION}")
    print("="*60)

    # Escenarios de prueba: Consultas que disparan mÃºltiples herramientas o reportes complejos
    queries = [
        "Dame el reporte ejecutivo de Marzo 2024 para la DIVISION FINANZAS.",
        "Compara la rotaciÃ³n de FFVV vs ADMI en el aÃ±o 2024.",
        "Dime la tendencia de rotaciÃ³n de Riesgos y compÃ¡rala con Operaciones en 2024.",
        "Â¿Hay alertas de talento crÃ­tico en la DIVISION COMERCIAL para Julio 2024?",
        "Haz un resumen ejecutivo anual del 2024 para toda la compaÃ±Ã­a."
    ]

    session_id = f"test-rpm-{int(time.time())}"
    results = []

    for i, query in enumerate(queries):
        print(f"\n[{i+1}/{len(queries)}] Enviando consulta: '{query}'")
        start_time = time.time()
        
        try:
            # Ejecutar consulta
            response = await router.route(query, session_id=session_id, profile="EJECUTIVO")
            duration = time.time() - start_time
            
            # Extraer telemetrÃ­a (inyectada por el router_logic actualizado)
            telemetry = {}
            if isinstance(response, dict):
                telemetry = response.get("telemetry", {})
            
            turns = telemetry.get("model_turns", "N/A")
            api_calls = telemetry.get("api_invocations_est", "N/A")
            tools = telemetry.get("tools_executed", [])
            
            print(f"âœ… Respuesta recibida en {duration:.2f}s")
            print(f"   ðŸ“Š TelemetrÃ­a: Turns={turns} | Est. API Calls={api_calls}")
            print(f"   ðŸ”§ Tools: {', '.join(tools) if tools else 'Ninguna'}")
            
            results.append({
                "query": query,
                "duration": duration,
                "turns": turns,
                "api_calls": api_calls,
                "tools": tools,
                "status": "success"
            })

            # PequeÃ±a pausa para no saturar instantÃ¡neamente si el lÃ­mite es muy bajo
            # Pero lo suficientemente corta para probar el RPM
            await asyncio.sleep(1)

        except Exception as e:
            print(f"âŒ Error en consulta: {e}")
            results.append({
                "query": query,
                "error": str(e),
                "status": "error"
            })
            if "429" in str(e) or "RESOURCE_EXHAUSTED" in str(e):
                print("ðŸš¨ BLOQUEO POR CUOTA (429) DETECTADO")

    # Resumen final
    print("\n" + "="*60)
    print("ðŸ“Š RESUMEN FINAL DEL TEST")
    total_calls = sum(r.get("api_calls", 0) for r in results if isinstance(r.get("api_calls"), int))
    total_duration = sum(r.get("duration", 0) for r in results if r.get("status") == "success")
    
    print(f"Consultas Exitosas: {len([r for r in results if r['status'] == 'success'])}/{len(queries)}")
    print(f"Total API Calls estimadas: {total_calls}")
    print(f"Tiempo Total de ejecuciÃ³n: {total_duration:.2f}s")
    if total_duration > 0:
        print(f"Promedio RPM (est): {(total_calls / total_duration) * 60:.2f}")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(run_rpm_test())
